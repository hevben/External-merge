Реализован алгоритм External merge sort с распараллеливанием
1. Определяем, сколько памяти RAM мы можем выделить для выполнения программы*
    *На самом деле нужно выделить чуть больше, а именно: (сколько RAM можем выделить)*K,
        где K - коэффициент, который показывает, во сколько раз больше памяти требуется алгоритму сортировки (который мы используем в пункте 3).
        К примеру, алгоритм merge sort имеет сложность по памяти O(n*log(n)), поэтому для него K~log(n). Для других алгоритмов может быть меньше
2. Делим исходный файл на участки размером, определённым выше. Их будет N = math.ceil(разм.файла/RAM)
3. Делим каждый из участков на cores частей и выполняем параллельно cores сортировок**, cores - количество ядер
    ** сортировки проводим встроенным алгоритмом sorted. Но при желании, можно легко заменить его на алгоритм merge sort (функция sort_m).
    Нам принципиально, что мы занимаемся слиянием больших (больше, чем RAM) файлов, а не слиянием всего, что можно, поэтому sort_merge я не использовал
4. В результате деления одного участка мы получаем cores списков (а в случае последнего участка, их количество <=cores). Всего таких участков N. Запишем эти списки в файлы
5. Сейчас у нас есть много файлов (отсортированных) в папке outputs. Задача - слить (merge) их. Она будет решаться следующим образом.
   а. Предположим, что файлов чётное количество. Тогда разделим их на пары и будем попарно сливать. В результате образуется N/2 файлов вдвое большего размера.
    Совершаем с ними пункт 6 до тех пор, пока не останется один файл
   б. Если файлов нечётное количество, то делаем пункт а со всеми, кроме одного (последнего), а последний сразу переносим на следующую итерацию (в нашем случае - путём переименования).
Попарное сливание в пункте 6 распараллеливаем: если пар больше, чем 1 (а их точно больше), сливания можно делать параллельно.
Это и делается в функции merge_sort

"Игрушечный" массив создаётся программой massiv.py. Он же сортируется программой multiproc.py. Размер RAM и размер файла указаны малыми для демонстрации, но и бОльшие размеры прекрасно работают.

Функция merge_parallel по своей сути повторяет функцию merge (просто слияние двух списков), но реализована для файлов, размером больше, чем RAM.
Конечный файл имеет имя, указанное в переменной final_path.
В конце происходит чтение из конечного файла и проверка отсортированности. Важно, что такую проверку мы можем делать только для наших игрушечных массивов (размером меньше реальной оперативной памяти компьютера)
